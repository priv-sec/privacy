{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4de2797-27b2-46b9-a4b6-42637e1401ee",
   "metadata": {},
   "source": [
    "# Exercise 1\n",
    "\n",
    "In this exercise you do not have to fill out missing TODOs. Now, we want you to **create** and **train** a neural network for the EMNIST dataset[1] (balanced version), an extension of the MNIST dataset.\n",
    "\n",
    "**Scoring System**: According to the following table, you will get points based on the **final test accuracy** of your model.\n",
    "\n",
    "| Test Acc | Points |\n",
    "| -------: | :----: |\n",
    "| <= 84%   |   1    |\n",
    "|    85%   |   2    |\n",
    "|    86%   |   3    |\n",
    "| >= 87%   |   4    |\n",
    "\n",
    "\n",
    "Here are some notes which might help you:\n",
    "* Please train your model not just once. We will use your code to retrain a model multiple times so you have to avoid lucky shots.\n",
    "* The preprocessing of the data can be realized with different transformations[2]\n",
    "* When changing the last activation function an appropriate loss function has to be selected and vice versa\n",
    "  (The given model uses the LogSoftmax in combination with the negative log likelihood loss)\n",
    "* There are two typical structures for a neural network:\n",
    "    * Only linear layers: Each linear layer is followed by an activation function.\n",
    "    * Convolutional layers followed by a few linear layers: ConvLayers each with its own activation function followed by a pooling function (standard: MaxPool2D). Afterwards, a few linear layers with activation functions are added.\n",
    "* You can also use convolutional layers[3] which are especially useful for image classification / segmentation tasks.\n",
    "\n",
    "[1] https://www.nist.gov/itl/products-and-services/emnist-dataset<br>\n",
    "[2] https://pytorch.org/vision/stable/transforms.html<br>\n",
    "[3] https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811b8b2b-ec8c-4ba1-a4d9-e2d37bbd4c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5652f7e-b384-4e3e-9281-382efecebf98",
   "metadata": {},
   "source": [
    "## Create and preprocess EMNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a86c4a1-fadf-400c-b3c8-884b6ba2d792",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(),])\n",
    "\n",
    "train_dataset = datasets.EMNIST(\"./data\", split=\"balanced\", train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.EMNIST(\"./data\", split=\"balanced\", train=False, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6ec148-1d1c-4e64-b051-08ae3ef4ddba",
   "metadata": {},
   "source": [
    "## Explore the data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f9f6a5-bb62-4ebf-bb24-dfc224c8e6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = list(string.digits + string.ascii_uppercase) + [\"a\", \"b\", \"d\", \"e\", \"f\", \"g\", \"h\", \"n\", \"q\", \"r\", \"t\"]\n",
    "\n",
    "figure = plt.figure(figsize=(10, 8))\n",
    "cols, rows = 5, 5\n",
    "sample_idx = torch.randint(0, 112800, size=(25,))\n",
    "\n",
    "for i in range(1, cols * rows + 1):\n",
    "    img, label = train_dataset.data[sample_idx[i-1]],  train_dataset.targets[sample_idx[i-1]]\n",
    "    figure.add_subplot(rows, cols, i)\n",
    "    plt.title(class_names[label])\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(torch.transpose(img.squeeze(), 1, 0), cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b705da10-a187-494c-b786-caf42bbb2f4c",
   "metadata": {},
   "source": [
    "## Create a neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0631eed9-1df9-4df2-9806-e999741fbf83",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    \n",
    "    ############\n",
    "    #   TODO   #\n",
    "    ############\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(784, 128)  # <- 28*28 = 784\n",
    "        self.fc2 = nn.Linear(128, 47)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.flatten(x, 1)  # <- Linear layers only process 2d data with shape (batch_size, data_size)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        output = F.log_softmax(x, dim=1)  # <- Works with <nll_loss> (negative log likelihood loss)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a087ef6-2af2-416d-8b54-630d72be88d8",
   "metadata": {},
   "source": [
    "## Train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e49c5ad-6eaf-410b-aa39-1e6dcb946cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer):\n",
    "    model.train()\n",
    "    for data, target in train_loader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    print(\"Train Loss: {:.6f}\".format(loss.item()))\n",
    "\n",
    "\n",
    "\n",
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item()  \n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    \n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print(\"Test set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n\".format(\n",
    "        test_loss, correct, len(test_loader.dataset), 100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc5dcd4d-8a81-49fc-9b4f-d33d99494338",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18cbdd02-de1b-46cd-9284-8d718deaed83",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "train_kwargs = {'batch_size': 32}\n",
    "test_kwargs = {'batch_size': 1000}\n",
    "    \n",
    "if use_cuda:\n",
    "    cuda_kwargs = {'num_workers': 2,\n",
    "                   'pin_memory': True,\n",
    "                   'shuffle': True}\n",
    "    train_kwargs.update(cuda_kwargs)\n",
    "    test_kwargs.update(cuda_kwargs)\n",
    "    \n",
    "train_loader = torch.utils.data.DataLoader(train_dataset,**train_kwargs)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, **test_kwargs)\n",
    "\n",
    "model = Net().to(device)\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "for epoch in range(1, 10):\n",
    "    print(f\"Epoch {epoch}\")\n",
    "    train(model, device, train_loader, optimizer)\n",
    "    test(model, device, test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorch (1 gpu)",
   "language": "python",
   "name": "pytorch-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
